{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup üç≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful Soup is a Python library that provides tools to scrape and parse HTML or XML documents. It simplifies the process of navigating and searching the HTML or XML tree, making it easier to extract the information you need. Here's a detailed guide on web scraping using Beautiful Soup:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *‚ñ∂Ô∏è* Import pakges\n",
    "\n",
    "from bs4 import BeautifulSoup<br/>\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *‚ñ∂Ô∏è* Make a request to the webpage:\n",
    "\n",
    "url = 'https://example.com' <br/>\n",
    "response = requests.get(url)\n",
    "\n",
    "\n",
    "### *‚ñ∂Ô∏è* Create a Beautiful Soup object:\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')<br/>\n",
    "\n",
    "Here, 'html.parser' is a parser provided by Python's standard library, but you can also use others like 'lxml' or 'html5lib' depending on your needs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *‚ñ∂Ô∏è*  Navigate and extract data:\n",
    "\n",
    "Use Beautiful Soup methods to navigate and extract information from the HTML. Some common methods include find(), find_all(), and select(). . <br/>\n",
    "\n",
    "### Find a specific element by tag and class\n",
    "\n",
    "title = soup.find('h1', class_='title')\n",
    "\n",
    "### Find all elements with a specific tag\n",
    "\n",
    "paragraphs = soup.find_all('p')\n",
    "\n",
    "### Extract text content from an element\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.text)\n",
    "\n",
    "<br/>\n",
    "\n",
    "You can also use CSS selectors with the select() method:\n",
    "\n",
    "### Using CSS selector\n",
    "title = soup.select('h1.title')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *‚ñ∂Ô∏è*  Handle exceptions:\n",
    "\n",
    "Web scraping is sensitive to changes in website structure. Always handle exceptions to avoid crashes.\n",
    "\n",
    "\n",
    "try: <br/>\n",
    "    title = soup.find('h1', class_='title').text <br/>\n",
    "except AttributeError as e: <br/>\n",
    "    title = None <br/>\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "### *‚ñ∂Ô∏è*  Iterate over multiple pages:\n",
    "\n",
    "If you need to scrape multiple pages, put the scraping logic inside a loop.\n",
    "\n",
    "\n",
    "for page_num in range(1, 6): <br/>\n",
    "    url = f'https://example.com/page/{page_num}' <br/>\n",
    "    response = requests.get(url) <br/>\n",
    "    soup = BeautifulSoup(response.text, 'html.parser') <br/>\n",
    "    # Scraping logic for each page\n",
    "\n",
    "<br/>\n",
    "\n",
    "### *‚ñ∂Ô∏è*  Advanced Usage:\n",
    "Handling different types of data:\n",
    "\n",
    "Beautiful Soup can handle both HTML and XML documents. Adjust the parser accordingly.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### For XML\n",
    "soup = BeautifulSoup(xml_data, 'xml')\n",
    "\n",
    "<br/>\n",
    "\n",
    "### *‚ñ∂Ô∏è*  Navigating the tree:\n",
    "\n",
    "Beautiful Soup provides various methods to navigate the HTML/XML tree, such as parent, children, descendants, and next_sibling.\n",
    "\n",
    "\n",
    "parent_element = soup.find('div') <br/>\n",
    "children_elements = parent_element.children\n",
    "\n",
    "<br/>\n",
    "\n",
    "### *‚ñ∂Ô∏è*  Modifying the HTML:\n",
    "\n",
    "You can modify the HTML content and write it back to a file.\n",
    "\n",
    "\n",
    "title = soup.find('h1') <br/>\n",
    "title.text = 'New Title' <br/>\n",
    "with open('new_page.html', 'w') as f: <br/>\n",
    "    f.write(str(soup))\n",
    "\n",
    "<br/>    \n",
    "\n",
    "### *‚ñ∂Ô∏è*  Handling forms:\n",
    "\n",
    "If you need to interact with forms on a website, you may need to use additional libraries like requests to submit data.\n",
    "\n",
    "\n",
    "payload = {'username': 'your_username', 'password': 'your_password'} <br/>\n",
    "response = requests.post('https://example.com/login', data=payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
